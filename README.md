# MLOps and deployment

This is a collection of simple, bite-size projects to learn MLOps tools and best practices.

`batch_inference_docker` sets up a batch inference job with a gradient boosted machine for regression. It employs Docker to create an easily reproducible, sharable and portable environment for our code to run in.

`real_time_API` will serve a predictive model as a REST API with endpoints for real-time inference.
